* Golang in action
** golang tools
*** build windows exe file on linux platform
	GOOS=windows GOARCH=amd64  go build ~/go/src/xchg.ai/sse/smalltest
    上面这个指令在Linux平台上可以编译出windows可执行文件
*** clean build out files
    go clean
*** build and running the excute file
    go run main.go xxx
    xxx 是参数
*** go env
    察看GO开发环境，可以为我们排查错误提供帮助
*** go install
    如果编译生成的是可执行文件，安装在$GOPATH/bin目录下
    如果编译生成的是可引用的库，安装在$GOPATH/pkg目录下
*** go fmt
*** go vet
*** go test
** golang doc
*** 终端查看文档：
	在当前目录下执行go doc, 输出当前目录下的文档信息；
    go doc packageName 列出这个包的信息，包括文档，方法，结构体等
    go doc json
    go doc json.Decoder
	go doc json.Decoder.Decode
    可以一步步缩小查找范围
*** 在线浏览文档：
*** 生成自己的文档（添加例子）：
* Golang test and benchmark
   func Test_XXXX(b *testing.B) {
	  //this is the testing code
   }

   //gen profile
   go test -bench=. -benchmem -memprofile memprofile.out -cpuprofile profile.out

   //check profile
   go tool pprof profile.out
* Golang web development
** Http Server
*** 服务器的主要职责：	
    Process dynamic requests: [处理动态请求] 
	Process incoming requests from users who browse the website, log into their accounts or post images.
    Serve static assets: [静态文件服务]
	Serve JavaScript, CSS and images to browsers to create a dynamic experience for the user.
    Accept connections: [网络连接管理]
	The HTTP Server must listen on a specific port to be able to accept connections from the internet.

** 路由器
   [[file:~/PlayGround/Golang/PlayWeb/hello_router.go][play with the gorilla router now!]]

** Connet with MySQL database
   Install a mysql server on a linux mechine
      
* Golang pprof
** profiling a golang program
  #+BEGIN_SRC
package main

import (
	"bufio"
	"flag"
	"fmt"
	"log"
	"os"
	"runtime"
	"runtime/pprof"
	"strconv"
	"sync"
)

const (
	DIRPATH    string = "./"
	FILENAME   string = "file"
	FILESUFFIX string = ".txt"
)

var fileIndexes []int = []int{1, 2, 3, 4}

var cpuprofile = flag.String("cpuprofile", "", "write cpu profile to `file`")
var memprofile = flag.String("memprofile", "", "write memory profile to `file`")

func main() {
	var wg sync.WaitGroup

	flag.Parse()
	if *cpuprofile != "" {
		f, err := os.Create(*cpuprofile)
		if err != nil {
			log.Fatal("could not create CPU profile: ", err)
		}
		defer f.Close() // error handling omitted for example
		if err := pprof.StartCPUProfile(f); err != nil {
			log.Fatal("could not start CPU profile: ", err)
		}
		defer pprof.StopCPUProfile()
	}

	for _, i := range fileIndexes {
		filePath := DIRPATH + FILENAME + strconv.Itoa(i) + FILESUFFIX

		wg.Add(1)
		go func() {
			defer wg.Done()

			file, err := os.Open(filePath)
			if err != nil {
				panic(err)
			}

			defer file.Close()

			scanner := bufio.NewScanner(file)
			for scanner.Scan() {
				fmt.Println(scanner.Text())
			}
		}()
	}

	wg.Wait()

	if *memprofile != "" {
		f, err := os.Create(*memprofile)
		if err != nil {
			log.Fatal("could not create memory profile: ", err)
		}
		defer f.Close() // error handling omitted for example
		runtime.GC()    // get up-to-date statistics
		if err := pprof.WriteHeapProfile(f); err != nil {
			log.Fatal("could not write memory profile: ", err)
		}
	}
}
  #+END_SRC
  the privious code show how to populate pprof in a golang program  

  after you build the project, the following command will generate the profile:
  =test_profile -cpuprofile test_profile.prof=

  then you can use the profile to invesgate the cpu usage sketch of the program:
  =go tool pprof test_pprof test_pprof.prof=

  when you in the pprof mode, you can type:
  =web=
  generate a graph of the program.
  
** using profile analyse routines stack
*** using net/http/pprof
#+BEGIN_SRC
package main

import (
	"fmt"
	"net/http"
	_ "net/http/pprof"
)

func main() {
	ip := "0.0.0.0:6060"
	if err := http.ListenAndServe(ip, nil); err != nil {
		fmt.Println("start pprof failed on %s\n", ip)
	}
}
#+END_SRC

open browser, and input http://localhost:6060/debug/pprof/
you will get a page.

use command line get profile message:
# 下载cpu profile，默认从当前开始收集30s的cpu使用情况，需要等待30s
go tool pprof http://localhost:6060/debug/pprof/profile                 # 30-second CPU profile
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=120     # wait 120s

# 下载heap profile
go tool pprof http://localhost:6060/debug/pprof/heap      # heap profile

# 下载goroutine profile
go tool pprof http://localhost:6060/debug/pprof/goroutine # goroutine profile

# 下载block profile
go tool pprof http://localhost:6060/debug/pprof/block     # goroutine blocking profile

# 下载mutex profile
go tool pprof http://localhost:6060/debug/pprof/mutex

*** using pprof get heap message
	go tool pprof http://localhost:6060/debug/pprof/heap
    top
    list
    traces
*** memory leak:
**** how to find memory leak?
     1. write your own batch file monitor the memory usage of your program:
#+BEGIN_SRC
#!/bin/bash
prog_name="demo1"
prog_mem=$(pidstat -r -u -h -C $prog_name |awk 'NR==4{print $12}')
time=$(date "+%Y-%m-%d %H:%M:%S")
echo $time"\tmemory(Byte)\t"$prog_mem >>~/record/prog_mem.log
#+END_SRC
        or you can use top | grep "your_programe_name" check memory useage
     2. use pprof
        a leak deamon:
#+BEGIN_SRC
package main

import (
	"fmt"
	"net/http"
	_ "net/http/pprof"
	"os"
	"time"
)

func main() {
	go func() {
		ip := "0.0.0.0:6060"
		if err := http.ListenAndServe(ip, nil); err != nil {
			fmt.Printf("start pprof failed on %s\n", ip)
			os.Exit(1)
		}
	}()

	outChan := make(chan int)

	//dead code, never read from the channel
	go func() {
		if false {
			<-outChan
		}
		select {}
	}()

	//spwan 10 routines per second,
	tick := time.Tick(time.Second / 10)
	i := 0
	for range tick {
		i++
		fmt.Println(i)
		alloc1(outChan)
	}
}

func alloc1(outChan chan<- int) {
	go alloc2(outChan)
}

func alloc2(outChan chan<- int) {
	go func() {
		defer fmt.Println("alloc-fm exit")
		//alloc some memory
		buf := make([]byte, 1024*1024*10)
		_ = len(buf)
		fmt.Println("alloc done")

		outChan <- 1
	}()
}
#+END_SRC
        in the privious code, main routine create 10 routine every second,
        beacause each routine is wait on "outChan<-1", so the allocated memory
        can not be freed.

		we use "go tool pprof" get the infomation of goroutines:

		go tool pprof http://localhost:6060/debug/pprof/goroutine
		
		do privious command two time, get:
		/Users/hjiang/pprof/pprof.goroutine.001.pb.gz
        /Users/hjiang/pprof/pprof.goroutine.002.pb.gz

		then, enter:
		go tool pprof -base /Users/hjiang/pprof/pprof.goroutine.001.pb.gz /Users/hjiang/pprof/pprof.goroutine.002.pb.gz
		get:
	    
* Golang concurrent pattern
** confinement [限定，不涉及同步原语]
   find some method or make a convetion to ensure that the information is only
   avaliable from one concurrent process(routine).
*** Ad hoc confinement
#+BEGIN_SRC
package main

import "fmt"

var data = make([]int, 4)

func main() {
	loopData := func(handleData chan<- int) {
		defer close(handleData)
		for i := range data {
			handleData <- data[i]
		}
	}

	handleData := make(chan int)
	go loopData(handleData)

	for num := range handleData {
		fmt.Println(num)
	}
}	
#+END_SRC

   in previous code snippet, we can see we only touch "data" slice in
the loopData routine. we have the criteria "in any single timestamp,
there is only one routine(process) control the information". so, this
can never make rece condition happen! 
   But if some day a newb come in then change the code, can you make
sure the criteria again? so we need compiler to enforce the criteria!

*** lexical confinement
#+BEGIN_SRC
package main

import "fmt"

func main() {
	chanOwner := func() <-chan int {
		results := make(chan int, 5)
		go func() {
			defer close(results)
			for i := 0; i <= 5; i++ {
				results <- i
			}
		}()
		return results
	}

	consumer := func(results <-chan int) {
		for result := range results {
			fmt.Printf("Received: %d\n", result)
		}
		fmt.Println("Done receive!")
	}

	results := chanOwner()
	consumer(results)
}
#+END_SRC

  in the previous code, "results"" is under chanOwner's lexical
scope. It confines the write aspect of this channel, so other
go routine can not write to it!

  channel is cocurrent safe by itself, now we inspect some no-concurrent
safe data structure.

#+BEGIN_SRC
    printData := func(wg *sync.WaitGroup, data []byte) {
		defer wg.Done()

		var buff bytes.Buffer
		for _, b := range data {
			fmt.Fprintf(&buff, "%c", b)
		}
		fmt.Println(buff.String())
	}

	var wg sync.WaitGroup
	wg.Add(2)
	data := []byte("golang")
	go printData(&wg, data[:3])
	go printData(&wg, data[3:])

	wg.Wait()
#+END_SRC

  in the previous code snippet, "data" is devided into two part,
and each part belongs to a difference routine.
  C(full) = A(part) + B(part);
  whatever you do in a routine has no effect on another.[also, you
can split data into k parts, and k routines deal with each part].

  pros and cons of confinement:
  pros:
  [1]. no need sync primitives, so good perforcement.
  [2]. the code is simpler to understand.

  cons:
  some times it is difficult to establish confinement.
** for--select 
*** send iteration variables to a channel
#+BEGIN_SRC
package main

import (
	"fmt"
	"io/ioutil"
	"strings"
	"time"
)

func main() {
	done := make(chan int)

	bySlice, err := ioutil.ReadFile("./main.go")
	if err != nil {
		panic(err)
	}

	strSlice := strings.Fields(string(bySlice))

	strStream := strStreamGen(strSlice, done)

	i := 0
	for {
		if i > 20 {
			done <- 1
			break
		}

		i++
		fmt.Println(<-strStream)
		time.Sleep(time.Second)
	}
}

func strStreamGen(strSlice []string, done chan int) <-chan string {
	strStream := make(chan string)
	go func() {
		for _, s := range strSlice {
			select {
			case <-done:
				return
			case strStream <- s:
			}
		}
	}()

	return strStream
}
#+END_SRC
    in the privious code snippet, in strStreamGen function, we create a string channel,
then create a new routine, loop over the string slice, put each element on the channel;
this function finally return a only-read channel out; 

    in main routine, we read on this channel; after get n value from the channel, we 
break the channel; then main routine finish; the channel is closed!

*** create goroutine infinitely waiting to be stopped
#+BEGIN_SRC
	done := make(chan int)

	go func() {
		for {
			select {
			case <-done:
				return
			default:
			}

			fmt.Println("Juming and Dancing!")
			time.Sleep(time.Second)
		}
	}()

	time.Sleep(time.Second * time.Duration(10))
	close(done)
#+END_SRC
** deal with goroutine leak
*** how go routine terminate?
**** it complete its work
**** due to an unrecoverable error, it can not be contiune
**** it has been told by others to stop working
*** an example of go routine leak: 
**** leak example:
#+BEGIN_SRC
    doWork := func(strings <-chan string) <-chan interface{} {
		completed := make(chan interface{})
		go func() {
			defer fmt.Println("doWork exited.")
			defer close(completed)
			for s := range strings {
				fmt.Println(s)
			}
		}()

		return completed
	}

	doWork(nil)

	time.Sleep(10 * time.Second)
	fmt.Println("Done")
#+END_SRC
  the main routine sleep 10 seconds, then exit; we can't see
"doWork exited." message print on the screen; the doWork routine is leaked!
as an counter example, we change the code and solving the leaking problem:
#+BEGIN_SRC
   doWork := func(strings <-chan string) <-chan interface{} {
		completed := make(chan interface{})
		go func() {
			defer fmt.Println("doWork exited.")
			defer close(completed)
			for s := range strings {
				fmt.Println(s)
			}
		}()

		return completed
	}

    genStrings := func() <-chan string {
			strings := make(chan string)
			go func() {
				defer close(strings)
				for i := 0; i < 10; i++ {
					strings <- strconv.Itoa(i)
				}
			}()

			return strings
    }

    strs := genStrings()
	doWork(strs)

	time.Sleep(10 * time.Second)
	fmt.Println("Done")
}
#+END_SRC
   This code soving the leaking problem by give doWork a
real channel!
*** use channel pass cancellation signal
 #+BEGIN_SRC
   doWork := func(done <-chan interface{}, strings <-chan string) <-chan interface{} {
		completed := make(chan interface{})
		go func() {
			defer fmt.Println("doWork exited.")
			defer close(completed)

			for {
				select {
				case s := <-strings:
					fmt.Println(s)
				case <-done:
					return
				}
			}
		}()

		return completed
	}

	done := make(chan interface{})
	terminated := doWork(done, nil)

	go func() {
		time.Sleep(1 * time.Second)
		fmt.Println("Canceling doWork goroutines...")
		close(done)
	}()

	<-terminated
	fmt.Println("Done")
 #+END_SRC

   in main routine we spawn a new routine, which close "done" channel after one second,
then doWork routine's "for-select" get this message, the doWork routine exit and close 
"completed" channel; main "<-terminated" wait on this closed channel and return. look!
no routine leak and deadlock happen!

CONVENTION: If a gorutine is responsible for creating a goroitine, it is also responsible
for ensure it can be stop the goroutine.
** or-channel
   or-channel is used to combine one or more done channels into
a single done channel, if any one of these channels is closed, then
the composed one will be closed.
   snippet code of or-channel:

#+BEGIN_SRC
    var or func(channels ...<-chan interface{}) <-chan interface{}

	or = func(channels ...<-chan interface{}) <-chan interface{} {
		switch len(channels) {
		case 0:
			return nil
		case 1:
			return channels[0]
		}

		orDone := make(chan interface{})
		go func() {
			defer close(orDone)

			switch len(channels) {
			case 2:
				select {
				case <-channels[0]:
				case <-channels[1]:
				}
			default:
				select {
				case <-channels[0]:
				case <-channels[1]:
				case <-channels[2]:
				case <-or(append(channels[3:], orDone)...):
				}
			}
		}()

		return orDone
	}
#+END_SRC

or-channel use case:
#+BEGIN_SRC
	sig := func(after time.Duration) <-chan interface{} {
		c := make(chan interface{})
		go func() {
			defer close(c)
			time.Sleep(after)
		}()

		return c
	}

	start := time.Now()
	<-or(
		sig(2*time.Hour),
		sig(5*time.Minute),
		sig(1*time.Second),
		sig(1*time.Hour),
		sig(1*time.Minute),
	)
	fmt.Printf("done after %v\n", time.Since(start))
#+END_SRC
    after one second, the process will terminated!
