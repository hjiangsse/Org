* Golang in action
** golang tools
*** build windows exe file on linux platform
	GOOS=windows GOARCH=amd64  go build ~/go/src/xchg.ai/sse/smalltest
    上面这个指令在Linux平台上可以编译出windows可执行文件
*** clean build out files
    go clean
*** build and running the excute file
    go run main.go xxx
    xxx 是参数
*** go env
    察看GO开发环境，可以为我们排查错误提供帮助
*** go install
    如果编译生成的是可执行文件，安装在$GOPATH/bin目录下
    如果编译生成的是可引用的库，安装在$GOPATH/pkg目录下
*** go fmt
*** go vet
*** go test
** golang doc
*** 终端查看文档：
	在当前目录下执行go doc, 输出当前目录下的文档信息；
    go doc packageName 列出这个包的信息，包括文档，方法，结构体等
    go doc json
    go doc json.Decoder
	go doc json.Decoder.Decode
    可以一步步缩小查找范围
*** 在线浏览文档：
*** 生成自己的文档（添加例子）：
* Golang test and benchmark
   func Test_XXXX(b *testing.B) {
	  //this is the testing code
   }

   //gen profile
   go test -bench=. -benchmem -memprofile memprofile.out -cpuprofile profile.out

   //check profile
   go tool pprof profile.out
* Golang web development
** Http Server
*** 服务器的主要职责：	
    Process dynamic requests: [处理动态请求] 
	Process incoming requests from users who browse the website, log into their accounts or post images.
    Serve static assets: [静态文件服务]
	Serve JavaScript, CSS and images to browsers to create a dynamic experience for the user.
    Accept connections: [网络连接管理]
	The HTTP Server must listen on a specific port to be able to accept connections from the internet.

** 路由器
   [[file:~/PlayGround/Golang/PlayWeb/hello_router.go][play with the gorilla router now!]]

** Connet with MySQL database
   Install a mysql server on a linux mechine
      
* Golang pprof
** profiling a golang program
  #+BEGIN_SRC
package main

import (
	"bufio"
	"flag"
	"fmt"
	"log"
	"os"
	"runtime"
	"runtime/pprof"
	"strconv"
	"sync"
)

const (
	DIRPATH    string = "./"
	FILENAME   string = "file"
	FILESUFFIX string = ".txt"
)

var fileIndexes []int = []int{1, 2, 3, 4}

var cpuprofile = flag.String("cpuprofile", "", "write cpu profile to `file`")
var memprofile = flag.String("memprofile", "", "write memory profile to `file`")

func main() {
	var wg sync.WaitGroup

	flag.Parse()
	if *cpuprofile != "" {
		f, err := os.Create(*cpuprofile)
		if err != nil {
			log.Fatal("could not create CPU profile: ", err)
		}
		defer f.Close() // error handling omitted for example
		if err := pprof.StartCPUProfile(f); err != nil {
			log.Fatal("could not start CPU profile: ", err)
		}
		defer pprof.StopCPUProfile()
	}

	for _, i := range fileIndexes {
		filePath := DIRPATH + FILENAME + strconv.Itoa(i) + FILESUFFIX

		wg.Add(1)
		go func() {
			defer wg.Done()

			file, err := os.Open(filePath)
			if err != nil {
				panic(err)
			}

			defer file.Close()

			scanner := bufio.NewScanner(file)
			for scanner.Scan() {
				fmt.Println(scanner.Text())
			}
		}()
	}

	wg.Wait()

	if *memprofile != "" {
		f, err := os.Create(*memprofile)
		if err != nil {
			log.Fatal("could not create memory profile: ", err)
		}
		defer f.Close() // error handling omitted for example
		runtime.GC()    // get up-to-date statistics
		if err := pprof.WriteHeapProfile(f); err != nil {
			log.Fatal("could not write memory profile: ", err)
		}
	}
}
  #+END_SRC
  the privious code show how to populate pprof in a golang program  

  after you build the project, the following command will generate the profile:
  =test_profile -cpuprofile test_profile.prof=

  then you can use the profile to invesgate the cpu usage sketch of the program:
  =go tool pprof test_pprof test_pprof.prof=

  when you in the pprof mode, you can type:
  =web=
  generate a graph of the program.
  
** using profile analyse routines stack
*** using net/http/pprof
#+BEGIN_SRC
package main

import (
	"fmt"
	"net/http"
	_ "net/http/pprof"
)

func main() {
	ip := "0.0.0.0:6060"
	if err := http.ListenAndServe(ip, nil); err != nil {
		fmt.Println("start pprof failed on %s\n", ip)
	}
}
#+END_SRC

open browser, and input http://localhost:6060/debug/pprof/
you will get a page.

use command line get profile message:
# 下载cpu profile，默认从当前开始收集30s的cpu使用情况，需要等待30s
go tool pprof http://localhost:6060/debug/pprof/profile                 # 30-second CPU profile
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=120     # wait 120s

# 下载heap profile
go tool pprof http://localhost:6060/debug/pprof/heap      # heap profile

# 下载goroutine profile
go tool pprof http://localhost:6060/debug/pprof/goroutine # goroutine profile

# 下载block profile
go tool pprof http://localhost:6060/debug/pprof/block     # goroutine blocking profile

# 下载mutex profile
go tool pprof http://localhost:6060/debug/pprof/mutex

*** using pprof get heap message
	go tool pprof http://localhost:6060/debug/pprof/heap
    top
    list
    traces
*** memory leak:
**** how to know memory leak? [如何知道程序中有内存泄露呢？]
     1. write your own batch file monitor the memory usage of your program:
#+BEGIN_SRC
#!/bin/bash
prog_name="demo1"
prog_mem=$(pidstat -r -u -h -C $prog_name |awk 'NR==4{print $12}')
time=$(date "+%Y-%m-%d %H:%M:%S")
echo $time"\tmemory(Byte)\t"$prog_mem >>~/record/prog_mem.log
#+END_SRC
        or you can use top | grep "your_programe_name" check memory useage
     2. use pprof
        a leak deamon:
#+BEGIN_SRC
package main

import (
	"fmt"
	"net/http"
	_ "net/http/pprof"
	"os"
	"time"
)

func main() {
	go func() {
		ip := "0.0.0.0:6060"
		if err := http.ListenAndServe(ip, nil); err != nil {
			fmt.Printf("start pprof failed on %s\n", ip)
			os.Exit(1)
		}
	}()

	outChan := make(chan int)

	//dead code, never read from the channel
	go func() {
		if false {
			<-outChan
		}
		select {}
	}()

	//spwan 10 routines per second,
	tick := time.Tick(time.Second / 10)
	i := 0
	for range tick {
		i++
		fmt.Println(i)
		alloc1(outChan)
	}
}

func alloc1(outChan chan<- int) {
	go alloc2(outChan)
}

func alloc2(outChan chan<- int) {
	go func() {
		defer fmt.Println("alloc-fm exit")
		//alloc some memory
		buf := make([]byte, 1024*1024*10)
		_ = len(buf)
		fmt.Println("alloc done")

		outChan <- 1
	}()
}
#+END_SRC
        in the privious code, main routine create 10 routine every second,
        beacause each routine is wait on "outChan<-1", so the allocated memory
        can not be freed.

		we use "go tool pprof" get the infomation of goroutines:

		go tool pprof http://localhost:6060/debug/pprof/goroutine
		
		do privious command two time, get:
		/Users/hjiang/pprof/pprof.goroutine.001.pb.gz
        /Users/hjiang/pprof/pprof.goroutine.002.pb.gz

		then, enter:
		go tool pprof -base /Users/hjiang/pprof/pprof.goroutine.001.pb.gz /Users/hjiang/pprof/pprof.goroutine.002.pb.gz
		when we input "top" command:
		[[file:./graph/leak_demo.png]]
		use 001.pb.gz as the base, we can see 002.pb.gz's routine number has increased 67!

**** how to locate where the leak happens?
	 1. use Web browser
		run the leak golang program, enter this address to the web browser:
        http://localhost:6060/debug/pprof/goroutine?debug=1
		result:
		[[file:./graph/leak_demo_web1.png]]
		
		total 1589: the total number of goroutine
        1584@xxxx : the total number of goroutine waiting in this place
        main.go:52 : the problem program line

		52: outChan <- 1 
        in the 52th line of the program, we write a value into an unbuffered channel,
        which will never be read out. So every goroutine write into this channel will
        wait forever, this is a leaking point!

		let's enter another line into the web browser:
		http://localhost:6060/debug/pprof/goroutine?debug=2
		result:
		[[file:./graph/leak_demo_web2.png]]

		[[file:./graph/leak_demo_web3.png]]
		
		you can also locate where is the leaking point!
	 2. use command line
		go tool pprof http://localhost:6060/debug/pprof/goroutine
		reuslt:
		[[file:./graph/leak_demo_web4.png]]
		
		a. enter top: find the routines number
        b. enter traces: find the call stack
        c. list: list code

		[[file:./graph/leak_demo_web5.png]]
* Golang benchmark
  https://golang.org/pkg/testing/
* Golang concurrent pattern
** confinement [限定，不涉及同步原语]
   find some method or make a convetion to ensure that the information is only
   avaliable from one concurrent process(routine).
*** Ad hoc confinement
#+BEGIN_SRC
package main

import "fmt"

var data = make([]int, 4)

func main() {
	loopData := func(handleData chan<- int) {
		defer close(handleData)
		for i := range data {
			handleData <- data[i]
		}
	}

	handleData := make(chan int)
	go loopData(handleData)

	for num := range handleData {
		fmt.Println(num)
	}
}	
#+END_SRC

   in previous code snippet, we can see we only touch "data" slice in
the loopData routine. we have the criteria "in any single timestamp,
there is only one routine(process) control the information". so, this
can never make rece condition happen! 
   But if some day a newb come in then change the code, can you make
sure the criteria again? so we need compiler to enforce the criteria!

*** lexical confinement
#+BEGIN_SRC
package main

import "fmt"

func main() {
	chanOwner := func() <-chan int {
		results := make(chan int, 5)
		go func() {
			defer close(results)
			for i := 0; i <= 5; i++ {
				results <- i
			}
		}()
		return results
	}

	consumer := func(results <-chan int) {
		for result := range results {
			fmt.Printf("Received: %d\n", result)
		}
		fmt.Println("Done receive!")
	}

	results := chanOwner()
	consumer(results)
}
#+END_SRC

  in the previous code, "results"" is under chanOwner's lexical
scope. It confines the write aspect of this channel, so other
go routine can not write to it!

  channel is cocurrent safe by itself, now we inspect some no-concurrent
safe data structure.

#+BEGIN_SRC
    printData := func(wg *sync.WaitGroup, data []byte) {
		defer wg.Done()

		var buff bytes.Buffer
		for _, b := range data {
			fmt.Fprintf(&buff, "%c", b)
		}
		fmt.Println(buff.String())
	}

	var wg sync.WaitGroup
	wg.Add(2)
	data := []byte("golang")
	go printData(&wg, data[:3])
	go printData(&wg, data[3:])

	wg.Wait()
#+END_SRC

  in the previous code snippet, "data" is devided into two part,
and each part belongs to a difference routine.
  C(full) = A(part) + B(part);
  whatever you do in a routine has no effect on another.[also, you
can split data into k parts, and k routines deal with each part].

  pros and cons of confinement:
  pros:
  [1]. no need sync primitives, so good perforcement.
  [2]. the code is simpler to understand.

  cons:
  some times it is difficult to establish confinement.
** for--select 
*** send iteration variables to a channel
#+BEGIN_SRC
package main

import (
	"fmt"
	"io/ioutil"
	"strings"
	"time"
)

func main() {
	done := make(chan int)

	bySlice, err := ioutil.ReadFile("./main.go")
	if err != nil {
		panic(err)
	}

	strSlice := strings.Fields(string(bySlice))

	strStream := strStreamGen(strSlice, done)

	i := 0
	for {
		if i > 20 {
			done <- 1
			break
		}

		i++
		fmt.Println(<-strStream)
		time.Sleep(time.Second)
	}
}

func strStreamGen(strSlice []string, done chan int) <-chan string {
	strStream := make(chan string)
	go func() {
		for _, s := range strSlice {
			select {
			case <-done:
				return
			case strStream <- s:
			}
		}
	}()

	return strStream
}
#+END_SRC
    in the privious code snippet, in strStreamGen function, we create a string channel,
then create a new routine, loop over the string slice, put each element on the channel;
this function finally return a only-read channel out; 

    in main routine, we read on this channel; after get n value from the channel, we 
break the channel; then main routine finish; the channel is closed!

*** create goroutine infinitely waiting to be stopped
#+BEGIN_SRC
	done := make(chan int)

	go func() {
		for {
			select {
			case <-done:
				return
			default:
			}

			fmt.Println("Juming and Dancing!")
			time.Sleep(time.Second)
		}
	}()

	time.Sleep(time.Second * time.Duration(10))
	close(done)
#+END_SRC
** deal with goroutine leak
*** how go routine terminate?
**** it complete its work
**** due to an unrecoverable error, it can not be contiune
**** it has been told by others to stop working
*** an example of go routine leak: 
**** leak example:
#+BEGIN_SRC
    doWork := func(strings <-chan string) <-chan interface{} {
		completed := make(chan interface{})
		go func() {
			defer fmt.Println("doWork exited.")
			defer close(completed)
			for s := range strings {
				fmt.Println(s)
			}
		}()

		return completed
	}

	doWork(nil)

	time.Sleep(10 * time.Second)
	fmt.Println("Done")
#+END_SRC
  the main routine sleep 10 seconds, then exit; we can't see
"doWork exited." message print on the screen; the doWork routine is leaked!
as an counter example, we change the code and solving the leaking problem:
#+BEGIN_SRC
   doWork := func(strings <-chan string) <-chan interface{} {
		completed := make(chan interface{})
		go func() {
			defer fmt.Println("doWork exited.")
			defer close(completed)
			for s := range strings {
				fmt.Println(s)
			}
		}()

		return completed
	}

    genStrings := func() <-chan string {
			strings := make(chan string)
			go func() {
				defer close(strings)
				for i := 0; i < 10; i++ {
					strings <- strconv.Itoa(i)
				}
			}()

			return strings
    }

    strs := genStrings()
	doWork(strs)

	time.Sleep(10 * time.Second)
	fmt.Println("Done")
}
#+END_SRC
   This code soving the leaking problem by give doWork a
real channel!
*** use channel pass cancellation signal
 #+BEGIN_SRC
   doWork := func(done <-chan interface{}, strings <-chan string) <-chan interface{} {
		completed := make(chan interface{})
		go func() {
			defer fmt.Println("doWork exited.")
			defer close(completed)

			for {
				select {
				case s := <-strings:
					fmt.Println(s)
				case <-done:
					return
				}
			}
		}()

		return completed
	}

	done := make(chan interface{})
	terminated := doWork(done, nil)

	go func() {
		time.Sleep(1 * time.Second)
		fmt.Println("Canceling doWork goroutines...")
		close(done)
	}()

	<-terminated
	fmt.Println("Done")
 #+END_SRC

   in main routine we spawn a new routine, which close "done" channel after one second,
then doWork routine's "for-select" get this message, the doWork routine exit and close 
"completed" channel; main "<-terminated" wait on this closed channel and return. look!
no routine leak and deadlock happen!

CONVENTION: If a gorutine is responsible for creating a goroitine, it is also responsible
for ensure it can be stop the goroutine.
** or-channel
   or-channel is used to combine one or more done channels into
a single done channel, if any one of these channels is closed, then
the composed one will be closed.
   snippet code of or-channel:

#+BEGIN_SRC
    var or func(channels ...<-chan interface{}) <-chan interface{}

	or = func(channels ...<-chan interface{}) <-chan interface{} {
		switch len(channels) {
		case 0:
			return nil
		case 1:
			return channels[0]
		}

		orDone := make(chan interface{})
		go func() {
			defer close(orDone)

			switch len(channels) {
			case 2:
				select {
				case <-channels[0]:
				case <-channels[1]:
				}
			default:
				select {
				case <-channels[0]:
				case <-channels[1]:
				case <-channels[2]:
				case <-or(append(channels[3:], orDone)...):
				}
			}
		}()

		return orDone
	}
#+END_SRC

or-channel use case:
#+BEGIN_SRC
	sig := func(after time.Duration) <-chan interface{} {
		c := make(chan interface{})
		go func() {
			defer close(c)
			time.Sleep(after)
		}()

		return c
	}

	start := time.Now()
	<-or(
		sig(2*time.Hour),
		sig(5*time.Minute),
		sig(1*time.Second),
		sig(1*time.Hour),
		sig(1*time.Minute),
	)
	fmt.Printf("done after %v\n", time.Since(start))
#+END_SRC
    after one second, the process will terminated!

	empty select:
#+BEGIN_SRC
package main

import (
	"fmt"
	"sync"
)

func main() {
	var wg sync.WaitGroup

	wg.Add(1)
	go func() {
		defer wg.Done()
		select {}
		fmt.Println("After select")
	}()

	wg.Wait()
}
#+END_SRC
    when we running the code, get this CLI output:
	[[file:./graph/empty_select.png]]
	we know dead lock happen, but when we commented the empty select code line:
    //select {}
	we get this:
	[[file:./graph/empty_select_cmt.png]]
	so, the empty select cause the dead lock!!!
** error handling in concurrent programming
     what can you do when errors occur in goroutine? let's see a little
   silly example:
#+BEGIN_SRC
package main

import (
	"fmt"
	"net/http"
)

func main() {
	checkStatus := func(done <-chan interface{}, urls ...string) <-chan *http.Response {
		responses := make(chan *http.Response)
		go func() {
			defer close(responses)
			for _, url := range urls {
				resp, err := http.Get(url)
				if err != nil {
					fmt.Println(err)  //:) only print the error in go routine, watch me!!!!
					continue
				}

				select {
				case <-done:
					return
				case responses <- resp:
				}
			}
		}()
		return responses
	}

	done := make(chan interface{})
	defer close(done)

	urls := []string{"https://www.baidu.com", "https://badhost"}
	for response := range checkStatus(done, urls...) {
		fmt.Printf("Response: %v\n", response.Status)
	}
}
#+END_SRC
    The previous code get sites responses, if success, move it into the result channel;
if failed, just print the error message in the work goroutine and continue work!!
    So the father routine(here is main routine) know nothing about the error(s) in his
child routine, thought he has the full context of the logic, he can do nothing with these
error(s).What a big tragedy!

    smater_example:
#+BEGIN_SRC
package main

import (
	"fmt"
	"net/http"
)

func main() {
	type Result struct {
		Error    error
		Response *http.Response
	}

	checkStatus := func(done <-chan interface{}, urls ...string) <-chan Result {
		results := make(chan Result)
		go func() {
			defer close(responses)
			for _, url := range urls {
				var result Result
				resp, err := http.Get(url)
				result = Result{err, resp}

				select {
				case <-done:
					return
				case results <- result:
				}
			}
		}()
		return results
	}

	done := make(chan interface{})
	defer close(done)

	urls := []string{"https://www.baidu.com", "https://badhost"}
	for result := range checkStatus(done, urls...) {
		if result.Error != nil {
			fmt.Printf("error: %v\n", result.Error)
		}
		fmt.Printf("Response: %v\n", results.Response.Status)
	}
}
#+END_SRC

    in previous smater example, we compose error result and normal result in
a struct called Result, and return a channel which type is this kind of struct!
now the main routine know all the result of his child routines! he can do 
what he want to deal with this messages!
** pipeline pattern
*** function pipeline in golang
**** batching processing
#+BEGIN_SRC go
package main

import "fmt"

func main() {
	multiply := func(values []int, multiplier int) []int {
		multipliedValues := make([]int, len(values))
		for i, v := range values {
			multipliedValues[i] = v * multiplier
		}
		return multipliedValues
	}

	add := func(values []int, adder int) []int {
		addedValues := make([]int, len(values))
		for i, v := range values {
			addedValues[i] = v + adder
		}
		return addedValues
	}

	ints := []int{1, 2, 3, 4}
	for _, v := range add(multiply(ints, 2), 1) {
		fmt.Println(v)
	}
}
#+END_SRC
    the privious code simulate a batching process scene. every
function eat a batch of data and pull out the same kind batch of
data. It is something just like functional programming:
#+BEGIN_SRC lisp
(defun multi-lst (lst n)
  (mapcar #'(lambda (x) (* x n))
		  lst))

(defun add-lst (lst n)
  (mapcar #'(lambda (x) (+ x n))
		  lst))

(add-lst (multi-lst '(1 2 3 4) 2) 1)
#+END_SRC
    you can see how nature functional programming(here common lisp)
implement this kind of batching pipeline process.
**** stream processing
#+BEGIN_SRC go
    multiply := func(value, multiplier int) int {
		return value * multiplier
	}

	add := func(value, adder int) int {
		return value + adder
	}

	ints := []int{1, 2, 3, 4}
	for _, v := range ints {
		fmt.Println(add(multiply(v, 2), 1))
	}
#+END_SRC
    the cons of the privious code is obvious: we have
to instantialize a new pipe line in each iteration.
*** use channel construct pipeline
*** channel processing[manifest previous example]
#+BEGIN_SRC go
package main

import "fmt"

func main() {
	generator := func(done <-chan interface{}, integers ...int) <-chan int {
		intStream := make(chan int)
		go func() {
			defer close(intStream)
			for _, i := range integers {
				select {
				case <-done:
					return
				case intStream <- i:
				}
			}
		}()
		return intStream
	}

	multiply := func(done <-chan interface{}, intStream <-chan int, multiplier int) <-chan int {
		multipliedStream := make(chan int)
		go func() {
			defer close(multipliedStream)
			for i := range intStream {
				select {
				case <-done:
					return
				case multipliedStream <- i * multiplier:
				}
			}
		}()
		return multipliedStream
	}

	add := func(done <-chan interface{}, intStream <-chan int, adder int) <-chan int {
		addedStream := make(chan int)
		go func() {
			defer close(addedStream)
			for i := range intStream {
				select {
				case <-done:
					return
				case addedStream <- i + adder:
				}
			}
		}()
		return addedStream
	}

	done := make(chan interface{})
	defer close(done)

	intStream := generator(done, 1, 2, 3, 4)
	pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2)

	for v := range pipeline {
		fmt.Println(v)
	}
}
#+END_SRC

what the generator has done? it converts a discrete set of values into a stream
of data on a channel.(This type of function is called generator)

the biggest difference in channel pipeline and function pipe line: use the channel
primitives, each stages of the pipeline is excuting cocurrently.
*** some handy generator
#+BEGIN_SRC
package main

import "fmt"

func main() {
	repeat := func(done <-chan interface{}, values ...interface{}) <-chan interface{} {
		valueStream := make(chan interface{})
		go func() {
			defer close(valueStream)
			for {
				for _, v := range values {
					select {
					case <-done:
						return
					case valueStream <- v:
					}
				}
			}
		}()
		return valueStream
	}

	take := func(done <-chan interface{}, valueStream <-chan interface{}, num int) <-chan interface{} {
		takeStream := make(chan interface{})
		go func() {
			defer close(takeStream)
			for i := 0; i < num; i++ {
				select {
				case <-done:
					return
				case takeStream <- <-valueStream:
				}
			}
		}()
		return takeStream
	}

	done := make(chan interface{})
	defer close(done)

	for num := range take(done, repeat(done, 10), 10) {
		fmt.Printf("%v ", num)
	}
}
#+END_SRC
    in the privious code, "repeat" will repeat the value you pass to it infinitely until you tell it to stop;
    "take" take the first num items off of its incoming stream if it is not closed so early!

	let's see a new kind of repeat:
#+BEGIN_SRC
repeatFn := func(done <-chan interface{}, fn func() interface{}) <-chan interface{} {
		valueStream := make(chan interface{})
		go func() {
			defer close(valueStream)
			for {
				select {
				case <-done:
					return
				case valueStream <- fn():
				}
			}
		}()
		return valueStream
	}
#+END_SRC
    "repeatFn" infinitely move the result of fn to the channel, we can use it like this:
#+BEGIN_SRC
	done := make(chan interface{})
	defer close(done)

	rand := func() interface{} {
		return rand.Int()
	}

	for num := range take(done, repeatFn(done, rand), 10) {
		fmt.Println(num)
	}
#+END_SRC
    an infinite channel of random integers.
**** interface{} and type assertion stage
	 in the previous example, we let each stage eat interface{} and pull out
 interface{}, how we want a stage deal with specific type?
 #+BEGIN_SRC
     toString := func(done <-chan interface{}, valueStream <-chan interface{}) <-chan string {
		 stringStream := make(chan string)
		 go func() {
			 defer close(stringStream)
			 for v := range valueStream {
				 select {
				 case <-done:
					 return
				 case stringStream <- v.(string):
				 }
			 }
		 }()
		 return stringStream
	 }
 #+END_SRC
 #+BEGIN_SRC
     var message string
	 for token := range toString(done, take(done, repeat(done, "a", "b"), 10)) {
		 message += token
	 }

	 fmt.Printf("message: %s...\n", message)
 #+END_SRC
** Fan-out, Fan-in
the the privious pipeline pattern has a big problem, if one of the middle stage
in the pipeline is computationally expensive, it will eclipse the performance 
overhead.

